🧠 GenAI Architect Program Week 8: Fine-Tuning & AI Protocols 🎯

📅 Learning Days 48 – 56 of 60 📘 Duration: Monday 20 – Sunday 26 October 2025

🧭 Overview

Week 8 marked the final chapter of the GenAI Architect journey — a blend of technical mastery and creative exploration.
This week bridged precision and possibility — from Fine-Tuning Models to Application Development Kits (ADK) and AI Protocols like MCP, ACP & A2A.

It was the week where the architect’s craft matured: learning how to train, adapt, and extend intelligence — both for AI systems and for oneself.

💡 “Fine-tuning models and fine-tuning minds share one truth — refinement builds brilliance.”

📅 Day 1 – Fine-Tuning Fundamentals

6 Lectures | 1 h 12 m 45 s

Topics Covered:

Intro to Fine-Tuning
Difference Between Parameter Tuning and Fine-Tuning
Intro to Unsloth Technique
How RAG is Different from Fine-Tuning
Fine-Tuning Methods & Types
Assignment – Explore the Unsloth Website

| Post | Title of Topics Covered                                 | Focus                                                                           |
| :--: | :------------------------------------------------------ | :------------------------------------------------------------------------------ |
|  01  | **Intro to Fine-Tuning**                                | Understanding how AI models are refined to specialize on domain data.           |
|  02  | **Difference Between Parameter Tuning and Fine-Tuning** | Differentiating between adjusting hyperparameters and retraining model weights. |
|  03  | **Intro to Unsloth Technique**                          | Exploring Unsloth — a fast, efficient open-source fine-tuning framework.        |
|  04  | **How RAG is Different from Fine-Tuning**               | Comparing retrieval-based approaches with permanent model adaptation.           |
|  05  | **Fine-Tuning Methods & Types**                         | LoRA, QLoRA, PEFT — lightweight, cost-effective fine-tuning frameworks.         |
|  06  | **Assignment – Explore Unsloth Website**                | Research task: exploring Unsloth’s documentation and sample use cases.          |


Key Takeaways

🔧 Fine-Tuning = Specialisation — refines a base model for domain-specific tasks.
🧠 Parameter vs Fine-Tuning — adjusting knobs versus rewiring neurons.
⚡ Unsloth makes fine-tuning efficient and open.
📚 RAG vs Fine-Tuning — retrieval vs integration of knowledge.

🌈 Reflection

Fine-tuning showed that intelligence grows through iteration and discipline.

🧩 “Fine-tuning transforms potential into precision.”

📅 Day 2 – Dataset Preparation & Instruction Tuning

4 Lectures | 52 m 10 s

Topics Covered

How to Prepare a Dataset
Fine-Tuning Model (Part 1)
Fine-Tuning Model (Part 2)
Fine-Tuning Instructions

| Post | Title of Topics Covered        | Focus                                                                  |
| :--: | :----------------------------- | :--------------------------------------------------------------------- |
|  07  | **How to Prepare a Dataset**   | Structuring clean, labelled, and balanced data for optimal learning.   |
|  08  | **Fine-Tuning Model (Part 1)** | Setting up the fine-tuning pipeline and objectives.                    |
|  09  | **Fine-Tuning Model (Part 2)** | Executing training and monitoring accuracy improvements.               |
|  10  | **Fine-Tuning Instructions**   | Writing effective instructions and prompts that guide model behaviour. |


Highlights

🧹 Dataset Preparation = 5S for AI — Sort, Set, Shine, Standardise, Sustain.
📊 Balanced datasets prevent bias and stabilise learning.
💬 Clear instruction design aligns AI responses with human intent.

🌿 Reflection

Data discipline is the soul of quality learning — for machines and humans alike.

💡 “The quality of your dataset defines the quality of your intelligence — both human and artificial.”

📅 Day 3 – Exploring ADK & AI Protocols

5 Lectures | 1 h 04 m 37 s

Topics Covered

What is ADK?
Build Your First Agent Using ADK
AI Protocols – MCP, ACP & A2A
A2A Hello World Program
Build Your Own MCP

| Post | Title of Topics Covered              | Focus                                                                                 |
| :--: | :----------------------------------- | :------------------------------------------------------------------------------------ |
|  11  | **What is ADK?**                     | Introduction to the Application Development Kit — a toolkit for agentic app building. |
|  12  | **Build Your First Agent using ADK** | Step-by-step creation of an AI agent using ADK principles.                            |
|  13  | **AI Protocols – MCP, ACP & A2A**    | Understanding how modern agents communicate and collaborate.                          |
|  14  | **A2A Hello World Program**          | Hands-on exploration of Agent-to-Agent messaging.                                     |
|  15  | **Build Your Own MCP**               | Designing a prototype for Model Context Protocol integration within n8n.              |


Learnings

🧩 ADK = Application Development Kit — a toolkit for building agentic applications.
🌐 MCP, ACP & A2A form the language of multi-agent communication.
🤖 A2A Hello World = the first digital handshake between agents.
🧱 Build Your Own MCP = design your own communication bridge inside n8n.

🔭 Reflection

ADK taught me that AI agents, like humans, grow stronger when they collaborate.

🌿 “ADK taught me that agents, like humans, thrive when they can connect and communicate.”

🪞 Weekly Reflection & Conclusion

Week 8 was the culmination of refinement and realisation.
From data to dialogue, every lesson reinforced that quality and curiosity must coexist.
The mindset of 5S, the precision of FMEA, and the imagination of ADK all merged into a complete architect’s ethos.

🌟 Personal Reflection

This week didn’t just close a program — it opened a path.
Fine-tuning my models mirrored fine-tuning myself.
With each workflow and reflection, I’ve learned that intelligence is not built by machines alone — it’s crafted by mindful humans.

"Completed GenAI Architect Program"

🪷 “The journey doesn’t end with a model; it continues with a mindset.”
---

⬅️ [Previous Week](../Week-07/README.md) 
